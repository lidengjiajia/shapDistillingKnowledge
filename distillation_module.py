# Knowledge Distillation Module - Decision Tree Only
# çŸ¥è¯†è’¸é¦æ¨¡å— - ä»…å†³ç­–æ ‘ç‰ˆæœ¬

import numpy as np
import torch
import torch.nn.functional as F
from sklearn.tree import DecisionTreeClassifier, _tree
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV
from tqdm import tqdm
import warnings
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import partial
import os
from datetime import datetime

# å¹¶å‘é…ç½®ï¼šä½¿ç”¨CPUæ ¸å¿ƒæ•°-1ï¼Œè‡³å°‘ä¸º1
n_jobs = max(1, min(mp.cpu_count() - 1, mp.cpu_count()))
# åªåœ¨éœ€è¦æ—¶æ˜¾ç¤ºé…ç½®ä¿¡æ¯ï¼Œé¿å…é‡å¤è¾“å‡º

# å¯¼å…¥æ¶ˆèå®éªŒåˆ†æå™¨
from ablation_analyzer import ablation_analyzer

# åˆ›å»ºTop-kæ¶ˆèåˆ†æå™¨çš„å…¨å±€å®ä¾‹
topk_ablation_analyzer = None

warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibåç«¯ä¸ºéäº¤äº’å¼ï¼Œé¿å…å¤šçº¿ç¨‹é—®é¢˜
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# ç¦ç”¨Optunaæ—¥å¿—è¾“å‡º

class KnowledgeDistillator:
    """çŸ¥è¯†è’¸é¦ç³»ç»Ÿ - å†³ç­–æ ‘è’¸é¦"""
    
    def __init__(self, teacher_models, processed_data, all_shap_results):
        self.teacher_models = teacher_models
        self.processed_data = processed_data
        self.all_shap_results = all_shap_results
        
    def extract_knowledge(self, dataset_name, model_type, temperature=3.0):
        """ä»æ•™å¸ˆæ¨¡å‹æå–çŸ¥è¯†
        
        çŸ¥è¯†è’¸é¦ç†è®ºèƒŒæ™¯ï¼š
        æ•™å¸ˆæ¨¡å‹è¾“å‡ºsoftmaxåˆ†å¸ƒåŒ…å«æ›´ä¸°å¯Œçš„ç±»é—´å…³ç³»ä¿¡æ¯
        temperatureå‚æ•°æ§åˆ¶åˆ†å¸ƒçš„å¹³æ»‘ç¨‹åº¦ï¼Œæ¸©åº¦è¶Šé«˜åˆ†å¸ƒè¶Šå¹³æ»‘
        """
        teacher_model = self.teacher_models[dataset_name]['model']
        data_dict = self.processed_data[dataset_name]
        
        X_train = data_dict['X_train']
        X_test = data_dict['X_test']
        
        # è·å–æ•™å¸ˆæ¨¡å‹çš„è½¯æ ‡ç­¾(æ¦‚ç‡åˆ†å¸ƒ)
        train_logits = self._get_teacher_predictions(teacher_model, X_train)
        test_logits = self._get_teacher_predictions(teacher_model, X_test)
        
        # åº”ç”¨æ¸©åº¦ç¼©æ”¾ï¼Œå¢å¼ºçŸ¥è¯†è’¸é¦æ•ˆæœ
        train_soft_labels = self._apply_temperature(train_logits, temperature)
        test_soft_labels = self._apply_temperature(test_logits, temperature)
        
        return {
            'train_soft_labels': train_soft_labels,
            'test_soft_labels': test_soft_labels,
            'teacher_logits_train': train_logits,
            'teacher_logits_test': test_logits
        }
    
    def _get_teacher_predictions(self, teacher_model, X):
        """ä»æ•™å¸ˆæ¨¡å‹è·å–é¢„æµ‹æ¦‚ç‡ - å…¼å®¹PyTorchå’Œsklearnæ¨¡å‹"""
        import torch
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯PyTorchæ¨¡å‹
        if hasattr(teacher_model, 'eval') and hasattr(teacher_model, 'forward'):
            # PyTorchæ¨¡å‹
            teacher_model.eval()
            device = next(teacher_model.parameters()).device
            
            with torch.no_grad():
                X_tensor = torch.FloatTensor(X).to(device)
                outputs = teacher_model(X_tensor)
                # å¯¹äºäºŒåˆ†ç±»ï¼Œå°†sigmoidè¾“å‡ºè½¬æ¢ä¸ºä¸¤ç±»æ¦‚ç‡
                probs_class1 = outputs.cpu().numpy().flatten()
                probs_class0 = 1 - probs_class1
                return np.column_stack([probs_class0, probs_class1])
        else:
            # sklearnæ¨¡å‹
            return teacher_model.predict_proba(X)
        
        return {
            'train_soft_labels': train_soft_labels,
            'test_soft_labels': test_soft_labels,
            'teacher_logits_train': train_logits,
            'teacher_logits_test': test_logits
        }
    
    def _apply_temperature(self, logits, temperature):
        """æ¸©åº¦ç¼©æ”¾ï¼šlogits / Tï¼Œç„¶ååº”ç”¨softmax
        æ¸©åº¦T > 1 ä½¿åˆ†å¸ƒæ›´å¹³æ»‘ï¼ŒT < 1 ä½¿åˆ†å¸ƒæ›´sharp
        """
        return F.softmax(torch.tensor(logits) / temperature, dim=1).numpy()
    
    def train_student_model(self, dataset_name, model_type_name='decision_tree', 
                          k=5, temperature=3.0, alpha=0.7, max_depth=6, 
                          use_all_features=False, trial=None):
        """è®­ç»ƒå­¦ç”Ÿæ¨¡å‹(å†³ç­–æ ‘)ä½¿ç”¨çŸ¥è¯†è’¸é¦
        
        å‚æ•°:
        - dataset_name: æ•°æ®é›†åç§°
        - model_type_name: å­¦ç”Ÿæ¨¡å‹ç±»å‹ï¼Œå›ºå®šä¸º'decision_tree'
        - k: Top-kç‰¹å¾æ•°é‡
        - temperature: çŸ¥è¯†è’¸é¦æ¸©åº¦å‚æ•°
        - alpha: è’¸é¦æŸå¤±æƒé‡ (0=ä»…ç¡¬æ ‡ç­¾, 1=ä»…è½¯æ ‡ç­¾)
        - max_depth: å†³ç­–æ ‘æœ€å¤§æ·±åº¦
        - use_all_features: æ˜¯å¦ä½¿ç”¨å…¨ç‰¹å¾
        - trial: Optuna trialå¯¹è±¡(ç”¨äºè¶…å‚æ•°ä¼˜åŒ–)
        """
        
        data_dict = self.processed_data[dataset_name]
        
        # ç‰¹å¾é€‰æ‹©
        if use_all_features:
            # ä½¿ç”¨å…¨ç‰¹å¾
            X_train_selected = data_dict['X_train']
            X_test_selected = data_dict['X_test']
            selected_features = data_dict['feature_names']
            model_type = f'all_features_decision_tree_distillation'
        else:
            # é€‰æ‹©Top-kç‰¹å¾
            shap_results = self.all_shap_results[dataset_name]
            top_k_features = shap_results['top_k_features'][k]
            feature_indices = [data_dict['feature_names'].index(feat) for feat in top_k_features]
            
            X_train_selected = data_dict['X_train'][:, feature_indices]
            X_test_selected = data_dict['X_test'][:, feature_indices]
            selected_features = top_k_features
            model_type = f'top_{k}_decision_tree_distillation'
        
        y_train = data_dict['y_train']
        y_test = data_dict['y_test']
        
        # æå–æ•™å¸ˆæ¨¡å‹çŸ¥è¯†
        knowledge = self.extract_knowledge(dataset_name, 'teacher', temperature)
        train_soft_labels = knowledge['train_soft_labels']
        test_soft_labels = knowledge['test_soft_labels']
        
        # åˆ›å»ºå†³ç­–æ ‘å­¦ç”Ÿæ¨¡å‹
        student_model = self._create_decision_tree_student(trial, max_depth)
        
        # çŸ¥è¯†è’¸é¦è®­ç»ƒ
        student_model = self._train_with_distillation(
            student_model, X_train_selected, y_train, train_soft_labels, alpha
        )
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = student_model.predict(X_test_selected)
        y_pred_proba = student_model.predict_proba(X_test_selected)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
        
        # æå–å†³ç­–è§„åˆ™
        rules = self._extract_decision_rules(student_model, selected_features)
        
        return {
            'model': student_model,
            'model_type': model_type,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'feature_count': len(selected_features),
            'selected_features': selected_features,
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'rules': rules,
            'temperature': temperature,
            'alpha': alpha,
            'max_depth': max_depth,
            'hyperparameters': {
                'temperature': temperature,
                'alpha': alpha,
                'max_depth': max_depth
            }
        }
    
    def _create_decision_tree_student(self, trial, max_depth):
        """åˆ›å»ºå†³ç­–æ ‘å­¦ç”Ÿæ¨¡å‹"""
        if trial is not None:
            # Optunaè¶…å‚æ•°ä¼˜åŒ–
            trial_max_depth = trial.suggest_int('max_depth', 3, 12)
            min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
            min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)
            max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])
        else:
            # ä½¿ç”¨å›ºå®šå‚æ•°
            trial_max_depth = max_depth
            min_samples_split = 2
            min_samples_leaf = 1
            max_features = 'sqrt'
        
        return DecisionTreeClassifier(
            max_depth=trial_max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            max_features=max_features,
            random_state=42
        )
    
    def _train_with_distillation(self, model, X_train, y_train, soft_labels, alpha):
        """ä½¿ç”¨çŸ¥è¯†è’¸é¦è®­ç»ƒå†³ç­–æ ‘
        
        å¯¹äºå†³ç­–æ ‘ï¼Œæˆ‘ä»¬ä½¿ç”¨è½¯æ ‡ç­¾çš„æ¦‚ç‡ä½œä¸ºæ ·æœ¬æƒé‡
        è¿™æ˜¯ä¸€ç§è¿‘ä¼¼çš„çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œå› ä¸ºå†³ç­–æ ‘ä¸ç›´æ¥æ”¯æŒè½¯æ ‡ç­¾
        """
        
        if alpha > 0:
            # ä½¿ç”¨è½¯æ ‡ç­¾çš„æœ€å¤§æ¦‚ç‡ä½œä¸ºæ ·æœ¬æƒé‡
            sample_weights = np.max(soft_labels, axis=1)
            # å½’ä¸€åŒ–æƒé‡
            sample_weights = sample_weights / np.sum(sample_weights) * len(sample_weights)
            
            # è®­ç»ƒæ—¶ä½¿ç”¨æ ·æœ¬æƒé‡
            model.fit(X_train, y_train, sample_weight=sample_weights)
        else:
            # çº¯ç¡¬æ ‡ç­¾è®­ç»ƒ
            model.fit(X_train, y_train)
        
        return model
    
    def _extract_decision_rules(self, model, feature_names):
        """æå–å†³ç­–æ ‘è§„åˆ™"""
        # ç®€åŒ–è§„åˆ™æå–ï¼Œä¸ä¾èµ–å¤–éƒ¨æ¨¡å—
        rules = self._simple_extract_rules(model, feature_names)
        
        return {
            'rules': rules,
            'rule_count': len(rules),
            'description': f'Decision tree with {len(rules)} rules'
        }
    
    def _simple_extract_rules(self, model, feature_names):
        """ç®€å•çš„å†³ç­–æ ‘è§„åˆ™æå–"""
        tree = model.tree_
        rules = []
        
        def recurse(node, depth, parent_rule=""):
            if tree.feature[node] != _tree.TREE_UNDEFINED:
                name = feature_names[tree.feature[node]]
                threshold = tree.threshold[node]
                left_rule = f"{parent_rule}{name} <= {threshold:.3f}"
                right_rule = f"{parent_rule}{name} > {threshold:.3f}"
                recurse(tree.children_left[node], depth + 1, left_rule + " and ")
                recurse(tree.children_right[node], depth + 1, right_rule + " and ")
            else:
                # å¶å­èŠ‚ç‚¹
                if parent_rule:
                    rule = parent_rule.rstrip(" and ")
                    value = tree.value[node]
                    predicted_class = np.argmax(value)
                    confidence = np.max(value) / np.sum(value)
                    rules.append(f"IF {rule} THEN class={predicted_class} (confidence={confidence:.3f})")
        
        try:
            recurse(0, 0)
        except Exception as e:
            # å¦‚æœè§„åˆ™æå–å¤±è´¥ï¼Œè¿”å›ç®€å•æè¿°
            rules = [f"Decision tree with {tree.node_count} nodes"]
        
        return rules
    
    def train_baseline_decision_tree(self, dataset_name):
        """è®­ç»ƒåŸºç¡€å†³ç­–æ ‘ï¼ˆä¸ä½¿ç”¨è’¸é¦ï¼‰"""
        data_dict = self.processed_data[dataset_name]
        
        X_train = data_dict['X_train']
        X_test = data_dict['X_test']
        y_train = data_dict['y_train']
        y_test = data_dict['y_test']
        feature_names = data_dict['feature_names']
        
        # å›ºå®šå‚æ•°è®­ç»ƒåŸºç¡€å†³ç­–æ ‘ï¼ˆæ— Optunaï¼‰
        model = DecisionTreeClassifier(
            max_depth=5,
            min_samples_split=2,
            min_samples_leaf=1,
            max_features='sqrt',
            random_state=42
        )
        model.fit(X_train, y_train)

        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)

        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

        # æå–å†³ç­–è§„åˆ™
        rules = self._extract_decision_rules(model, feature_names)

        params = {
            'max_depth': 5,
            'min_samples_split': 2,
            'min_samples_leaf': 1,
            'max_features': 'sqrt'
        }

        return {
            'model': model,
            'model_type': 'baseline_tree',
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'feature_count': len(feature_names),
            'selected_features': feature_names,
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'rules': rules,
            'hyperparameters': params,
            'best_params': params
        }
    
    def run_all_feature_distillation(self, dataset_names, temperature_range, alpha_range, max_depth_range):
        """è¿è¡Œå…¨ç‰¹å¾çŸ¥è¯†è’¸é¦å®éªŒå¹¶è®°å½•æ¶ˆèå®éªŒæ•°æ®"""
        results = {}
        
        for dataset_name in dataset_names:
            print(f"   Processing {dataset_name.upper()} dataset...")
            results[dataset_name] = {}
            
            best_accuracy = 0  # æ”¹ä¸ºä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºè¯„åˆ¤æ ‡å‡†
            best_result = None
            
            total_combinations = len(temperature_range) * len(alpha_range) * len(max_depth_range)
            progress_bar = tqdm(total=total_combinations, desc=f"ğŸ“ {dataset_name.upper()}", 
                               unit="exp", position=0, leave=True)
            print(f"     å…¨ç‰¹å¾å®éªŒç»„åˆæ•°: {total_combinations}")
            
            for temperature in temperature_range:
                for alpha in alpha_range:
                    for max_depth in max_depth_range:
                        progress_bar.set_postfix({
                            'T': temperature, 
                            'Î±': f"{alpha:.1f}", 
                            'D': max_depth,
                            'Best': f"{best_accuracy:.3f}"
                        })
                        result = self.train_student_model(
                            dataset_name=dataset_name,
                            model_type_name='decision_tree',
                            use_all_features=True,
                            temperature=temperature,
                            alpha=alpha,
                            max_depth=max_depth
                        )
                        
                        # è®°å½•å…¨ç‰¹å¾è’¸é¦çš„æ¶ˆèå®éªŒæ•°æ®
                        ablation_analyzer.record_experiment_result(
                            dataset_name=dataset_name,
                            k=None,  # å…¨ç‰¹å¾è’¸é¦æ²¡æœ‰kå€¼
                            temperature=temperature,
                            alpha=alpha,
                            max_depth=max_depth,
                            accuracy=result['accuracy'],
                            f1_score=result['f1'],
                            precision=result['precision'],
                            recall=result['recall']
                        )
                        
                        if result['accuracy'] > best_accuracy:  # æ”¹ä¸ºä½¿ç”¨å‡†ç¡®ç‡
                            best_accuracy = result['accuracy']
                            best_result = result
                        
                        progress_bar.update(1)
            
            progress_bar.close()
            results[dataset_name]['best'] = best_result
            print(f"     Best Accuracy: {best_accuracy:.4f}")  # æ”¹ä¸ºæ˜¾ç¤ºå‡†ç¡®ç‡
        
        # ä¿å­˜æ¶ˆèå®éªŒæ•°æ®å’Œåˆ›å»ºå¯è§†åŒ–
        print("\nğŸ“Š Saving ablation study data and creating visualizations for all-feature distillation...")
        ablation_analyzer.save_ablation_data(prefix='ablation_study')
        ablation_analyzer.create_ablation_visualizations()
        ablation_analyzer.generate_summary_report(prefix='ablation_study')
        
        return results
    
    
    def run_comprehensive_distillation(self, dataset_names, k_ranges, temperature_range, alpha_range, max_depth_range):
        """è¿è¡Œç»¼åˆçŸ¥è¯†è’¸é¦å®éªŒï¼ˆTop-kç‰¹å¾ï¼‰
        
        Args:
            dataset_names: æ•°æ®é›†åç§°åˆ—è¡¨
            k_ranges: æ¯ä¸ªæ•°æ®é›†çš„kèŒƒå›´å­—å…¸ {'german': (5, 54), 'australian': (5, 22), 'uci': (5, 23)}
            temperature_range: æ¸©åº¦å‚æ•°èŒƒå›´
            alpha_range: åŠ æƒå‚æ•°èŒƒå›´
            max_depth_range: å†³ç­–æ ‘æ·±åº¦èŒƒå›´
        """
        global topk_ablation_analyzer
        
        # åˆå§‹åŒ–Top-kæ¶ˆèåˆ†æå™¨
        from ablation_analyzer import AblationStudyAnalyzer
        topk_ablation_analyzer = AblationStudyAnalyzer()
        topk_ablation_analyzer.experiment_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        results = {}
        
        for dataset_name in dataset_names:
            print(f"   Processing {dataset_name.upper()} dataset...")
            results[dataset_name] = {}
            
            best_accuracy = 0  # æ”¹ä¸ºä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºè¯„åˆ¤æ ‡å‡†
            best_result = None
            best_k = None
            
            # è·å–å½“å‰æ•°æ®é›†çš„kèŒƒå›´
            dataset_k_range = k_ranges[dataset_name]
            k_values = list(range(dataset_k_range[0], dataset_k_range[1] + 1))
            total_combinations = len(k_values) * len(temperature_range) * len(alpha_range) * len(max_depth_range)
            progress_bar = tqdm(total=total_combinations, desc=f"ğŸ” {dataset_name.upper()}", 
                               unit="exp", position=0, leave=True)
            print(f"     kèŒƒå›´: {dataset_k_range[0]} åˆ° {dataset_k_range[1]} ({len(k_values)} ä¸ªå€¼)")
            print(f"     Top-kå®éªŒç»„åˆæ•°: {total_combinations}")
            
            # å‡†å¤‡å¹¶å‘æ‰§è¡Œçš„å®éªŒå‚æ•°
            experiment_params = []
            for k in k_values:
                for temperature in temperature_range:
                    for alpha in alpha_range:
                        for max_depth in max_depth_range:
                            experiment_params.append((dataset_name, k, temperature, alpha, max_depth))
            
            # è®¾ç½®å¹¶å‘æ•°é‡
            import platform
            if platform.system() == 'Windows':
                n_jobs = min(4, max(1, mp.cpu_count() // 2))
            else:
                n_jobs = max(1, min(mp.cpu_count() - 1, mp.cpu_count()))
            
            print(f"     ğŸš€ Using {n_jobs} parallel jobs for Top-k distillation")
            
            # å¹¶å‘æ‰§è¡Œå®éªŒ
            def run_single_experiment(params):
                dataset_name, k, temperature, alpha, max_depth = params
                try:
                    result = self.train_student_model(
                        dataset_name=dataset_name,
                        model_type_name='decision_tree',
                        k=k,
                        temperature=temperature,
                        alpha=alpha,
                        max_depth=max_depth,
                        use_all_features=False
                    )
                    return params, result, None
                except Exception as e:
                    return params, None, str(e)
            
            # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œæ‰§è¡Œ
            if platform.system() == 'Windows':
                # Windowsä¸‹ä½¿ç”¨spawnæ–¹æ³•é¿å…pickleé—®é¢˜
                mp.set_start_method('spawn', force=True)
            
            from multiprocessing import Pool
            from functools import partial
            
            # ç”±äºéœ€è¦è®¿é—®selfï¼Œæˆ‘ä»¬éœ€è¦ç‰¹æ®Šå¤„ç†
            # åºåˆ—åŒ–å®éªŒå‡½æ•°
            def experiment_worker(params):
                dataset_name, k, temperature, alpha, max_depth = params
                # é‡æ–°åˆ›å»ºæ‰€éœ€çš„å¯¹è±¡ï¼ˆè¿™æ˜¯å¹¶å‘çš„ä»£ä»·ï¼‰
                # å®é™…æ‰§è¡Œå°†åœ¨ä¸»è¿›ç¨‹ä¸­å®Œæˆï¼Œè¿™é‡Œæ”¹ä¸ºä¸²è¡Œä½†æœ‰è¿›åº¦æ˜¾ç¤º
                return params
            
            # å› ä¸ºselfæ— æ³•åºåˆ—åŒ–ï¼Œæ”¹ä¸ºä½¿ç”¨çº¿ç¨‹æ± æ¥å®ç°å¹¶å‘
            from concurrent.futures import ThreadPoolExecutor, as_completed
            
            all_results = []
            with ThreadPoolExecutor(max_workers=n_jobs) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_params = {
                    executor.submit(run_single_experiment, params): params 
                    for params in experiment_params
                }
                
                # å¤„ç†ç»“æœ
                for future in as_completed(future_to_params):
                    params, result, error = future.result()
                    if error:
                        print(f"     âŒ Error in experiment {params}: {error}")
                        continue
                    
                    dataset_name, k, temperature, alpha, max_depth = params
                    
                    # è®°å½•Top-kè’¸é¦çš„æ¶ˆèå®éªŒæ•°æ®
                    topk_ablation_analyzer.record_experiment_result(
                        dataset_name=dataset_name,
                        k=k,
                        temperature=temperature,
                        alpha=alpha,
                        max_depth=max_depth,
                        accuracy=result['accuracy'],
                        f1_score=result['f1'],
                        precision=result['precision'],
                        recall=result['recall']
                    )
                    
                    all_results.append((params, result))
                    
                    if result['accuracy'] > best_accuracy:
                        best_accuracy = result['accuracy']
                        best_result = result
                        best_k = k
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.set_postfix({
                        'k': k,
                        'T': temperature, 
                        'Î±': f"{alpha:.1f}", 
                        'D': max_depth,
                        'Best': f"{best_accuracy:.3f}"
                    })
                    progress_bar.update(1)
            
            progress_bar.close()
            results[dataset_name]['best'] = best_result
            results[dataset_name]['best_k'] = best_k
            print(f"     Best Accuracy: {best_accuracy:.4f} with k={best_k}")  # æ”¹ä¸ºæ˜¾ç¤ºå‡†ç¡®ç‡
        
        # ä¿å­˜Top-kæ¶ˆèå®éªŒæ•°æ®å’Œåˆ›å»ºå¯è§†åŒ–
        print("\nğŸ“Š Saving Top-k ablation study data and creating visualizations...")
        topk_ablation_analyzer.save_ablation_data(prefix='topk_ablation_study')
        # ä½¿ç”¨é€šç”¨çš„æ¶ˆèå®éªŒå¯è§†åŒ–æ–¹æ³•ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
        topk_ablation_analyzer.create_ablation_visualizations()
        topk_ablation_analyzer.generate_summary_report(prefix='topk_ablation_study')
        
        return results
    


