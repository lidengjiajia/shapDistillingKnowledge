"""
ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ - ç²¾ç®€ç‰ˆä¸»ç¨‹åº
åªä¿å­˜æ ¸å¿ƒç»“æœï¼šåŸºçº¿æ¨¡å‹ã€è’¸é¦æ¨¡å‹ã€SHAPå›¾ã€æ¶ˆèå®éªŒæ—¶é—´
"""

import os
import warnings
import torch
import numpy as np
import pandas as pd
from datetime import datetime
import time
import random

# è®¾ç½®éšæœºç§å­
def set_global_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

set_global_seed(42)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_preprocessing import DataPreprocessor
from neural_models import train_all_teacher_models
from baseline_models import train_all_baseline_models, save_baseline_results_to_excel
from shap_analysis import SHAPAnalyzer
from distillation_module import KnowledgeDistillator

warnings.filterwarnings('ignore')

def main():
    """ç²¾ç®€ç‰ˆä¸»å‡½æ•° - åªä¿å­˜æ ¸å¿ƒç»“æœ"""
    
    print("="*80)
    print("ğŸ¯ ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ - ç²¾ç®€ç‰ˆ")
    print("="*80)
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs('results', exist_ok=True)
    
    # è®°å½•æ—¶é—´
    time_log = {}
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    try:
        # ========================
        # 1. æ•°æ®é¢„å¤„ç†
        # ========================
        print(f"\nğŸ”„ Phase 1: Data Preprocessing")
        start_time = time.time()
        
        preprocessor = DataPreprocessor()
        processed_data = preprocessor.process_all_datasets()
        
        time_log['data_preprocessing'] = time.time() - start_time
        print(f"   âœ… å®Œæˆ ({time_log['data_preprocessing']:.2f}s)")
        
        # ========================
        # 2. åŸºçº¿æ¨¡å‹è®­ç»ƒï¼ˆä¿å­˜åˆ°Excelï¼‰
        # ========================
        print(f"\nğŸ”§ Phase 2: Baseline Models Training")
        start_time = time.time()
        
        baseline_results_all, baseline_trainer = train_all_baseline_models(processed_data)
        # Excelå·²åœ¨train_all_baseline_modelsä¸­è‡ªåŠ¨ä¿å­˜
        
        time_log['baseline_training'] = time.time() - start_time
        print(f"   âœ… å®Œæˆ ({time_log['baseline_training']:.2f}s)")
        
        # ========================
        # 3. ç¥ç»ç½‘ç»œæ•™å¸ˆæ¨¡å‹è®­ç»ƒ
        # ========================
        print(f"\nğŸ§  Phase 3: Teacher Models Training")
        start_time = time.time()
        
        teacher_models = train_all_teacher_models(processed_data)
        
        time_log['teacher_training'] = time.time() - start_time
        print(f"   âœ… å®Œæˆ ({time_log['teacher_training']:.2f}s)")
        
        # ========================
        # 4. SHAPåˆ†æï¼ˆä¿å­˜4ä¸ªæ•°æ®é›†çš„SHAPå›¾ï¼‰
        # ========================
        print(f"\nğŸ” Phase 4: SHAP Feature Importance Analysis")
        start_time = time.time()
        
        shap_analyzer = SHAPAnalyzer(processed_data)
        shap_analyzer.train_decision_trees()
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”ŸæˆSHAPå›¾
        shap_files = []
        for dataset_name in ['german', 'australian', 'uci', 'xinwang']:
            data_dict = processed_data[dataset_name]
            n_features = len(data_dict['feature_names'])
            
            # è®¡ç®—SHAPå€¼
            shap_results = shap_analyzer.compute_shap_values(
                dataset_name, 
                top_k_range=(5, n_features)
            )
            
            # ç”ŸæˆSHAPå¯è§†åŒ–
            shap_path = f"results/shap_{dataset_name}_features.png"
            shap_analyzer.visualize_shap_importance(dataset_name, shap_results, save_path=shap_path)
            shap_files.append(shap_path)
            print(f"   ğŸ“Š {dataset_name.upper()}: {shap_path}")
        
        # å­˜å‚¨æ‰€æœ‰SHAPç»“æœç”¨äºåç»­è’¸é¦
        all_shap_results = {}
        for dataset_name in ['german', 'australian', 'uci', 'xinwang']:
            data_dict = processed_data[dataset_name]
            n_features = len(data_dict['feature_names'])
            all_shap_results[dataset_name] = shap_analyzer.compute_shap_values(
                dataset_name, 
                top_k_range=(5, n_features)
            )
        
        time_log['shap_analysis'] = time.time() - start_time
        print(f"   âœ… å®Œæˆ ({time_log['shap_analysis']:.2f}s)")
        
        # ========================
        # 5. çŸ¥è¯†è’¸é¦å®éªŒï¼ˆä¿å­˜æœ€ä¼˜æ¨¡å‹å†³ç­–è§„åˆ™åˆ°Excelï¼‰
        # ========================
        # 5. çŸ¥è¯†è’¸é¦å®éªŒï¼ˆæ¶ˆèå®éªŒï¼‰
        # ========================
        print(f"\nğŸŒŸ Phase 5: Knowledge Distillation Ablation Study")
        start_time = time.time()
        
        distillator = KnowledgeDistillator(teacher_models, processed_data, all_shap_results)
        
        # Top-kè’¸é¦å®éªŒ
        k_ranges = {}
        for dataset_name in ['german', 'australian', 'uci', 'xinwang']:
            data_dict = processed_data[dataset_name]
            n_features = len(data_dict['feature_names'])
            k_ranges[dataset_name] = (5, n_features)
        
        distillation_results = distillator.run_comprehensive_distillation(
            dataset_names=['german', 'australian', 'uci', 'xinwang'],
            k_ranges=k_ranges,
            temperature_range=[1, 2, 3, 4, 5],
            alpha_range=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            max_depth_range=[4, 5, 6, 7, 8]
        )
        
        time_log['distillation'] = time.time() - start_time
        print(f"   âœ… å®Œæˆ ({time_log['distillation']:.2f}s)")
        
        # ========================
        # 6. 4ç§æ¨¡å‹å¯¹æ¯”å®éªŒ
        # ========================
        print(f"\nğŸ”¬ Phase 6: Four-Model Comparison")
        start_time = time.time()
        
        # æå–æ¯ä¸ªæ•°æ®é›†çš„æœ€ä½³å‚æ•°
        best_params = {}
        for dataset_name, results in distillation_results.items():
            if 'best' in results:
                best_result = results['best']
                if best_result is None:
                    print(f"[è­¦å‘Š] æ•°æ®é›† {dataset_name} æœªæ‰¾åˆ°æœ€ä½³å‚æ•°ï¼Œæ‰€æœ‰å®éªŒå‡å¤±è´¥æˆ–æ— æ•ˆã€‚")
                best_params[dataset_name] = {
                    'k': results.get('best_k', 10),
                    'temperature': (best_result or {}).get('temperature', 3.0),
                    'alpha': (best_result or {}).get('alpha', 0.5),
                    'max_depth': (best_result or {}).get('max_depth', 5)
                }
        
        # è¿è¡Œ4ç§æ¨¡å‹å¯¹æ¯”
        comparison_results = distillator.run_four_model_comparison(
            dataset_names=['german', 'australian', 'uci', 'xinwang'],
            best_params=best_params
        )
        
        # ä¿å­˜4ç§æ¨¡å‹å¯¹æ¯”ç»“æœåˆ°Excel
        four_model_excel = distillator.save_four_model_comparison_to_excel(comparison_results, timestamp)
        
        time_log['four_model_comparison'] = time.time() - start_time
        print(f"   âœ… å®Œæˆ ({time_log['four_model_comparison']:.2f}s)")
        
        # ========================
        # 7. ä¿å­˜æ—¶é—´ç»Ÿè®¡åˆ°Excel
        # ========================
        save_time_log_to_excel(time_log, timestamp)
        
        # ========================
        # æ€»ç»“
        # ========================
        print(f"\n{'='*80}")
        print(f"ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
        print(f"{'='*80}")
        print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   1ï¸âƒ£  åŸºçº¿æ¨¡å‹ç»“æœ: results/baseline_models_comparison_{timestamp}.xlsx")
        print(f"   2ï¸âƒ£  4ç§æ¨¡å‹å¯¹æ¯”ç»“æœ: {four_model_excel}")
        print(f"   3ï¸âƒ£  SHAPç‰¹å¾å›¾ (4ä¸ª): results/shap_*_features.png")
        print(f"   4ï¸âƒ£  æ¶ˆèå®éªŒæ•°æ®: results/topk_ablation_study_{timestamp}.csv")
        print(f"   5ï¸âƒ£  è¿è¡Œæ—¶é—´ç»Ÿè®¡: results/time_log_{timestamp}.xlsx")
        print(f"{'='*80}")
        print(f"\nğŸ“Š 4ç§æ¨¡å‹å¯¹æ¯”è¯´æ˜:")
        print(f"   â€¢ Baseline Decision Tree - åŸå§‹å†³ç­–æ ‘ï¼ˆæ— è’¸é¦ï¼‰")
        print(f"   â€¢ Teacher Neural Network - ç¥ç»ç½‘ç»œæ•™å¸ˆæ¨¡å‹")
        print(f"   â€¢ FKD - å…¨ç‰¹å¾çŸ¥è¯†è’¸é¦")
        print(f"   â€¢ SHAP-KD - Top-kç‰¹å¾çŸ¥è¯†è’¸é¦")
        print(f"{'='*80}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise e


def save_time_log_to_excel(time_log, timestamp):
    """ä¿å­˜è¿è¡Œæ—¶é—´ç»Ÿè®¡åˆ°Excel"""
    filename = f"results/time_log_{timestamp}.xlsx"
    
    data = []
    for phase, duration in time_log.items():
        data.append({
            'Phase': phase,
            'Duration_seconds': duration,
            'Duration_minutes': duration / 60
        })
    
    df = pd.DataFrame(data)
    
    # æ·»åŠ æ€»æ—¶é—´
    total_time = sum(time_log.values())
    df = pd.concat([df, pd.DataFrame([{
        'Phase': 'TOTAL',
        'Duration_seconds': total_time,
        'Duration_minutes': total_time / 60
    }])], ignore_index=True)
    
    df.to_excel(filename, index=False)
    print(f"   â±ï¸  è¿è¡Œæ—¶é—´å·²ä¿å­˜: {filename}")
    
    return filename


if __name__ == "__main__":
    main()
