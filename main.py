"""
ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ - ä¸»ç¨‹åº
Credit Scoring Model Optimization System - Main Program

åŸºäºSHAPç‰¹å¾é‡è¦æ€§åˆ†æå’ŒçŸ¥è¯†è’¸é¦çš„ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ
æ¨¡å—åŒ–æ¶æ„ï¼Œæ”¯æŒæ‰©å±•å‚æ•°ç»„åˆå’Œæ”¹è¿›çš„ç”¨æˆ·ä½“éªŒ
"""

import os
import warnings
import torch
import numpy as np
from tqdm import tqdm
import random

# ============================
# å…¨å±€éšæœºç§å­è®¾ç½® - ç¡®ä¿å®éªŒå¯é‡å¤
# ============================
def set_global_seed(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

# åœ¨å¯¼å…¥ä»»ä½•æ¨¡å—ä¹‹å‰è®¾ç½®éšæœºç§å­
set_global_seed(42)

# è§£å†³ä¸­æ–‡è·¯å¾„ç¼–ç é—®é¢˜
import locale
import tempfile
import multiprocessing
try:
    locale.setlocale(locale.LC_ALL, 'C')
except:
    pass

# è®¾ç½®ä¸´æ—¶ç›®å½•ä¸ºè‹±æ–‡è·¯å¾„é¿å…ç¼–ç é—®é¢˜
temp_dir = "C:\\temp_ml"
if not os.path.exists(temp_dir):
    os.makedirs(temp_dir)
os.environ['TEMP'] = temp_dir
os.environ['TMP'] = temp_dir

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_preprocessing import DataPreprocessor
from neural_models import train_all_teacher_models
from shap_analysis import SHAPAnalyzer
from distillation_module import KnowledgeDistillator
from result_manager import ResultManager
from ablation_analyzer import AblationStudyAnalyzer

warnings.filterwarnings('ignore')

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ"""
    
    from multiprocessing import cpu_count
    
    print("="*80)
    print("ğŸ¯ ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ | Credit Scoring Model Optimization System")
    print("   åŸºäºSHAPç‰¹å¾é‡è¦æ€§åˆ†æå’ŒçŸ¥è¯†è’¸é¦ | SHAP + Knowledge Distillation")
    print("   å¢å¼ºç‰ˆ - æ”¯æŒå†³ç­–æ ‘æ·±åº¦å‚æ•°å’Œæ¶ˆèå®éªŒåˆ†æ")
    print("="*80)
    print("ğŸ”§ å¹¶å‘é…ç½®:")
    print(f"   â€¢ CPUæ ¸å¿ƒæ•°: {cpu_count()}")
    print(f"   â€¢ å¹¶å‘å·¥ä½œè¿›ç¨‹: {max(1, min(cpu_count() - 1, cpu_count()))} (ä¿ç•™1ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ)")
    print("="*80)
    print("ğŸ“Š å®éªŒå‚æ•°é…ç½®:")
    print("   â€¢ Top-kç‰¹å¾: k=åŠ¨æ€èŒƒå›´ (5åˆ°æ¯ä¸ªæ•°æ®é›†çš„ç‰¹å¾æ€»æ•°)")
    print("     - German: k=5åˆ°54 (50ä¸ªå€¼)")
    print("     - Australian: k=5åˆ°22 (18ä¸ªå€¼)")
    print("     - UCI: k=5åˆ°23 (19ä¸ªå€¼)")
    print("   â€¢ åŠ æƒæ¯”ä¾‹å‚æ•°: Î±=0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0") 
    print("   â€¢ æ¸©åº¦å‚æ•°: T=1,2,3,4,5") 
    print("   â€¢ å†³ç­–æ ‘æ·±åº¦: D=4,5,6,7,8")
    print("   â€¢ åŸºçº¿æ¨¡å‹: å›ºå®šå‚æ•°ï¼ˆmax_depth=5ï¼‰ï¼Œæ— å‚æ•°ä¼˜åŒ–")
    print("   â€¢ å†³ç­–æ ‘å­¦ç”Ÿæ¨¡å‹çŸ¥è¯†è’¸é¦")
    print("="*80)
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs('results', exist_ok=True)
    
    try:
        # ========================
        # 1. æ•°æ®é¢„å¤„ç†é˜¶æ®µ
        # ========================
        print(f"\nğŸ”„ Phase 1: Data Preprocessing")
        print(f"   Loading and preprocessing datasets...")
        
        preprocessor = DataPreprocessor()
        processed_data = preprocessor.process_all_datasets()
        
        print(f"   âœ… Data preprocessing completed")
        for dataset_name, data_dict in processed_data.items():
            print(f"     â€¢ {dataset_name.upper()}: {data_dict['X_train'].shape[0]} train, {data_dict['X_test'].shape[0]} test samples")
        
        # ========================
        # 2. æ•™å¸ˆæ¨¡å‹è®­ç»ƒé˜¶æ®µ
        # ========================
        teacher_models = train_all_teacher_models(processed_data)
        
        # ========================
        # 3. SHAPç‰¹å¾é‡è¦æ€§åˆ†æ
        # ========================
        print(f"\nğŸ” Phase 3: SHAP Feature Importance Analysis")
        print(f"   Training decision trees for SHAP analysis...")
        
        shap_analyzer = SHAPAnalyzer(processed_data)
        
        # å…ˆè®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ç”¨äºSHAPåˆ†æ
        shap_analyzer.train_decision_trees()
        
        # è®¡ç®—SHAPå€¼ - ä½¿ç”¨åŠ¨æ€kèŒƒå›´
        all_shap_results = {}
        for dataset_name in ['uci', 'german', 'australian']:
            # æ¯ä¸ªæ•°æ®é›†ä½¿ç”¨å…¶ç‰¹å¾æ€»æ•°ä½œä¸ºkçš„æœ€å¤§å€¼
            data_dict = processed_data[dataset_name]
            n_features = len(data_dict['feature_names'])
            all_shap_results[dataset_name] = shap_analyzer.compute_shap_values(
                dataset_name, 
                top_k_range=(5, n_features)
            )
        
        # åˆ›å»ºç»„åˆSHAPå¯è§†åŒ–
        shap_viz_path = shap_analyzer.create_combined_shap_visualization(all_shap_results)
        
        print(f"   âœ… SHAP analysis completed")
        print(f"     â€¢ Combined visualization: {shap_viz_path}")
        
        # ========================
        # åˆå§‹åŒ–çŸ¥è¯†è’¸é¦å™¨
        # ========================
        distillator = KnowledgeDistillator(teacher_models, processed_data, all_shap_results)
        
        # ========================
        # 4. åŸºç¡€å†³ç­–æ ‘è®­ç»ƒï¼ˆå¯¹æ¯”åŸºå‡†ï¼‰
        # ========================
        print(f"\nğŸŒ³ Phase 4: Baseline Decision Tree Training")
        print(f"   Training baseline decision trees for comparison...")
        
        baseline_results = {}
        for dataset_name in ['uci', 'german', 'australian']:
            baseline_results[dataset_name] = distillator.train_baseline_decision_tree(dataset_name)
        
        print(f"   âœ… Baseline decision tree training completed")
        for dataset_name, result in baseline_results.items():
            print(f"     â€¢ {dataset_name.upper()}: Accuracy: {result['accuracy']:.4f}")
        
        # ========================
        # 5. å…¨ç‰¹å¾çŸ¥è¯†è’¸é¦å®éªŒ
        # ========================
        print(f"\nğŸŒŸ Phase 5: All-Feature Knowledge Distillation")
        print(f"   Running all-feature distillation with grid search...")
        
        all_feature_distillation_results = distillator.run_all_feature_distillation(
            dataset_names=['uci', 'german', 'australian'],
            temperature_range=[1, 2, 3, 4, 5],   # Temperature: 1-5 (é—´éš”1)
            alpha_range=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Alpha: 0.0-1.0 (é—´éš”0.1)
            max_depth_range=[4, 5, 6, 7, 8]  # Depth: 4-8
        )
        
        print(f"   âœ… All-feature knowledge distillation completed")
        
        # ========================
        # 6. Top-kçŸ¥è¯†è’¸é¦å®éªŒ
        # ========================
        print(f"\nğŸ§ª Phase 6: Top-k Knowledge Distillation Experiments")
        print(f"   Running comprehensive distillation with parameter optimization...")
        
        # è·å–æ¯ä¸ªæ•°æ®é›†çš„åŠ¨æ€kèŒƒå›´ (ä»5åˆ°æ¯ä¸ªæ•°æ®é›†çš„ç‰¹å¾æ€»æ•°)
        k_ranges = {}
        for dataset_name in ['uci', 'german', 'australian']:
            data_dict = processed_data[dataset_name]
            n_features = len(data_dict['feature_names'])
            k_ranges[dataset_name] = (5, n_features)
            print(f"   {dataset_name.upper()}: kèŒƒå›´ 5 åˆ° {n_features} ({n_features-4} ä¸ªå€¼)")
        
        # Top-kç‰¹å¾è’¸é¦å®éªŒ
        top_k_distillation_results = distillator.run_comprehensive_distillation(
            dataset_names=['uci', 'german', 'australian'],
            k_ranges=k_ranges,         # æ¯ä¸ªæ•°æ®é›†çš„åŠ¨æ€kèŒƒå›´
            temperature_range=[1, 2, 3, 4, 5],   # Temperature: 1-5 (é—´éš”1)
            alpha_range=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Alpha: 0.0-1.0 (é—´éš”0.1)
            max_depth_range=[4, 5, 6, 7, 8]        # Depth: 4-8
        )
        
        print(f"   âœ… Top-k knowledge distillation experiments completed")
        
        # ========================
        # 7. ç»“æœæ±‡æ€»å’Œå¯¼å‡º
        # ========================
        print(f"\nğŸ“Š Phase 7: Results Analysis and Export")
        print(f"   Generating simplified results...")
        
        result_manager = ResultManager()
        
        # 1. ç”Ÿæˆå››ä¸ªæ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        comparison_excel_path = result_manager.generate_model_comparison_table(
            teacher_models, baseline_results, all_feature_distillation_results, top_k_distillation_results
        )
        
        # 2. SHAPç‰¹å¾é‡è¦æ€§å¯è§†åŒ–å·²åœ¨Phase 3ä¸­å®Œæˆï¼Œæ— éœ€é‡å¤ç”Ÿæˆ
        
        # 3. æå–æœ€ä¼˜å…¨ç‰¹å¾è’¸é¦è§„åˆ™
        all_feature_rules_path = result_manager.extract_best_all_feature_rules(all_feature_distillation_results, processed_data)
        
        # 4. æå–æœ€ä¼˜Top-kè’¸é¦è§„åˆ™
        topk_rules_path = result_manager.extract_best_topk_rules(top_k_distillation_results, processed_data)
        
        # 5. æ¸…ç†ä¸éœ€è¦çš„æ–‡ä»¶ - å·²ç¦ç”¨ï¼Œä¿ç•™æ‰€æœ‰æ–‡ä»¶
        # result_manager.clean_output_files()
        
        print(f"\nğŸ‰ System Execution Completed Successfully!")
        print(f"   ğŸ“ ç”Ÿæˆçš„æ ¸å¿ƒæ–‡ä»¶:")
        print(f"   ğŸ“Š 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”Excel: {comparison_excel_path}")
        print(f"   ğŸ¯ 2. SHAPç‰¹å¾é‡è¦æ€§å›¾: {shap_viz_path}")
        print(f"   ğŸŒ³ 3. å…¨ç‰¹å¾è’¸é¦è§„åˆ™txt: {all_feature_rules_path}")
        print(f"   ğŸŒ² 4. Top-kè’¸é¦è§„åˆ™txt: {topk_rules_path}")
        print(f"   ğŸ“ˆ 5. å…¨ç‰¹å¾æ¶ˆèå®éªŒç»“æœ(Excel+å›¾)å·²ç”Ÿæˆ")
        print(f"   ğŸ“Š 6. Top-kæ¶ˆèå®éªŒç»“æœ(Excel+å›¾)å·²ç”Ÿæˆ")
        
        # æ˜¾ç¤ºæœ€ä¼˜è’¸é¦é…ç½®ä¿¡æ¯
        print(f"\nğŸ† æœ€ä¼˜é…ç½®æ€»ç»“:")
        
        # æ˜¾ç¤ºå…¨ç‰¹å¾è’¸é¦çš„æœ€ä¼˜é…ç½®
        print(f"   ğŸŒŸ å…¨ç‰¹å¾è’¸é¦æœ€ä¼˜é…ç½®:")
        for dataset_name in ['uci', 'german', 'australian']:
            if dataset_name in all_feature_distillation_results:
                best_config = result_manager._find_best_all_feature_config(all_feature_distillation_results[dataset_name])
                if best_config:
                    print(f"     â€¢ {dataset_name.upper()}æ•°æ®é›†:")
                    print(f"       - å‚æ•°: T={best_config.get('temperature', 'N/A')}, "
                          f"Î±={best_config.get('alpha', 'N/A')}, D={best_config.get('max_depth', 'N/A')}")
                    print(f"       - æ€§èƒ½: Accuracy={best_config.get('accuracy', 0):.4f}, F1={best_config.get('f1', 0):.4f}")
        
        # æ˜¾ç¤ºTop-kè’¸é¦çš„æœ€ä¼˜é…ç½®
        print(f"   ğŸ§ª Top-kè’¸é¦æœ€ä¼˜é…ç½®:")
        for dataset_name in ['uci', 'german', 'australian']:
            if dataset_name in top_k_distillation_results:
                best_config = result_manager._find_best_topk_config(top_k_distillation_results[dataset_name])
                if best_config:
                    print(f"     â€¢ {dataset_name.upper()}æ•°æ®é›†:")
                    print(f"       - å‚æ•°: k={best_config.get('k', 'N/A')}, T={best_config.get('temperature', 'N/A')}, "
                          f"Î±={best_config.get('alpha', 'N/A')}, D={best_config.get('max_depth', 'N/A')}")
                    print(f"       - æ€§èƒ½: Accuracy={best_config.get('accuracy', 0):.4f}, F1={best_config.get('f1', 0):.4f}")
        
    except Exception as e:
        print(f"\nâŒ Error during system execution: {str(e)}")
        import traceback
        traceback.print_exc()
        raise e

if __name__ == "__main__":
    main()
